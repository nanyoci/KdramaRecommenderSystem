{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WebScraping.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iaq0OyS5HYTc"
      },
      "source": [
        "TODO: \"Airs\": to be aired like M2020"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvn_jLnQTI2S"
      },
      "source": [
        "import bs4 \n",
        "from urllib.request import urlopen as uReq\n",
        "from urllib.request import Request\n",
        "from bs4 import BeautifulSoup as soup\n",
        "import re\n",
        "from math import ceil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIfwllKZgA-I"
      },
      "source": [
        "def read_page(my_url):\n",
        "  uClient = uReq(Request(my_url, headers={'User-Agent': 'Mozilla/5.0'}))\n",
        "  page_html = uClient.read()\n",
        "  uClient.close()\n",
        "  page_soup = soup(page_html, \"html.parser\")\n",
        "  return page_soup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9RZo5NaEzPg"
      },
      "source": [
        "my_url =  \"https://mydramalist.com/search?adv=titles&ty=68&co=3&re=2019,2020&st=3&so=top\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvODbTJtTjgm"
      },
      "source": [
        "page_soup = read_page(my_url)\n",
        "def find_total_result(page_soup = page_soup):\n",
        "  total_res = page_soup.findAll(\"p\", {\"class\": \"m-b-sm pull-right\"})\n",
        "  total = int(re.search(r'\\d+', total_res[0].text.strip()).group())\n",
        "  return total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgKEDkLfjkvs"
      },
      "source": [
        "def find_all_titles(page_soup = page_soup):\n",
        "  preview_container = page_soup.findAll(\"div\", {\"class\": \"col-lg-8 col-md-8\"})\n",
        "  previews = preview_container[0].findAll(\"div\", {\"class\": \"row\"})\n",
        "  query = []\n",
        "  for prev in previews:\n",
        "    query.append(prev.a[\"href\"])\n",
        "  return query"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOW8RfF4lpMK"
      },
      "source": [
        "Get all previews first then get details of each drama"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxaDP4p0vl3Y"
      },
      "source": [
        "def find_title(page_soup = page_soup):\n",
        "  try:\n",
        "   title = page_soup.h1.a[\"title\"]\n",
        "  except:\n",
        "    title = \"\"\n",
        "  return title\n",
        "\n",
        "def find_description(page_soup = page_soup):\n",
        "  try:\n",
        "    description = page_soup.findAll(\"div\", {\"class\": \"show-synopsis\"})[0]\n",
        "    description = description.p.text\n",
        "    p = re.compile('(\\n\\(Source: .*\\).*|Edit Translation)')\n",
        "    description = p.sub('', description)\n",
        "  except:\n",
        "    description = \"\"\n",
        "  return description"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MFR1TXDvr_H"
      },
      "source": [
        "def find_meta1(page_soup = page_soup):\n",
        "  details = page_soup.findAll(\"div\", {\"class\": \"show-detailsxss\"})[0]\n",
        "  detail_dict = dict.fromkeys([\"Genres\" , \"Screenwriter\", \"Director\", \"Tags\", ])\n",
        "\n",
        "  for name, _ in detail_dict.items():\n",
        "    try:\n",
        "      parent = details.find(\"b\", text=\"{}:\".format(name)).parent\n",
        "      detail_html = parent.findAll(\"a\")\n",
        "      for i in range(len(detail_html)):\n",
        "        detail_html[i] = detail_html[i].text\n",
        "      detail_dict[name] = detail_html\n",
        "    except:\n",
        "      detail_dict[name] = []\n",
        "  if(len(detail_dict['Tags'])>0):\n",
        "    detail_dict['Tags'].pop()\n",
        "  return detail_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNUNh78TOvcJ"
      },
      "source": [
        "def find_meta2(page_soup = page_soup):\n",
        "  detail_dict = dict.fromkeys([\"Episodes\", \"Aired\", \"Aired On\", \"Original Network\", \"Score\", \"Ranked\", \"Popularity\", \"Watchers\"])\n",
        "  ul = page_soup.findAll('ul', {\"class\": \"list m-a-0 hidden-md-up\"})[0]\n",
        "  for name, _ in detail_dict.items():\n",
        "    try:\n",
        "      detail = ul.find('b', text = \"{}:\".format(name)).parent\n",
        "      detail = detail.text\n",
        "      p = re.compile('(.*: )')\n",
        "      detail = p.sub('', detail)\n",
        "      detail_dict[name] = detail\n",
        "    except:\n",
        "      detail_dict[name] = \"\"\n",
        "  return detail_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34-3W8eugRY9"
      },
      "source": [
        "def find_casts(page_soup = page_soup):\n",
        "  actors = page_soup.findAll(\"div\", { \"class\": \"col-xs-8 col-sm-7 p-a-0\"})\n",
        "  casts = list()\n",
        "  for actor in actors:\n",
        "    try:\n",
        "      role = actor.findAll(\"small\", {\"class\": \"text-muted\"})[0]\n",
        "      role = role.text\n",
        "      if(role == \"Main Role\"):\n",
        "        casts.append(actor.a['title'])\n",
        "    except:\n",
        "      continue\n",
        "  return casts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooEzVFS1aQHL"
      },
      "source": [
        "def preprocess_meta(meta):\n",
        "  #popularity\n",
        "  if(len(meta[\"Popularity\"])>0):\n",
        "    p = re.compile('#')\n",
        "    meta[\"Popularity\"] = p.sub('', meta[\"Popularity\"])\n",
        "    try:\n",
        "      meta[\"Popularity\"] =int(meta[\"Popularity\"])\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  #rank\n",
        "  if(len(meta[\"Ranked\"])>0):\n",
        "    p = re.compile('#')\n",
        "    meta[\"Ranked\"] = p.sub('', meta[\"Ranked\"])\n",
        "    try:\n",
        "      meta[\"Ranked\"] =int(meta[\"Ranked\"])\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  #episodes\n",
        "  if(len(meta[\"Episodes\"])>0):\n",
        "      meta[\"Episodes\"] =int(meta[\"Episodes\"])\n",
        "\n",
        "  #score \n",
        "  if(len(meta[\"Score\"])>0):\n",
        "    try:\n",
        "      results = re.search('(\\d|.+|N/A) \\(scored by (\\d+(?:,\\d+)?) users?\\)', meta[\"Score\"])\n",
        "      user_rated = results.group(2)\n",
        "      user_rated = user_rated.replace(',', '')\n",
        "      user_rated = int(user_rated)\n",
        "      if(user_rated == 0):\n",
        "        score = 0\n",
        "      else:\n",
        "        score = float(results.group(1))\n",
        "      meta[\"User_rated\"] = user_rated\n",
        "      meta[\"Score\"] = score\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  #watchers\n",
        "  if(len(meta[\"Watchers\"])>0):\n",
        "    meta[\"Watchers\"] = meta[\"Watchers\"].replace(',', '')\n",
        "    meta[\"Watchers\"] =int(meta[\"Watchers\"])\n",
        "\n",
        "  #networks\n",
        "  if (len(meta[\"Original Network\"])>0):\n",
        "    try:\n",
        "      networks = meta[\"Original Network\"].split()\n",
        "      networks = list(set(networks))\n",
        "      networks = (',').join(networks)\n",
        "      meta[\"Original Network\"] = networks\n",
        "    except:\n",
        "      pass\n",
        "  \n",
        "  return meta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C9eA794Ks6s"
      },
      "source": [
        "url = 'https://mydramalist.com/36269-doctor-playbook'\n",
        "#page_soup = individual drama detail page\n",
        "def get_kdrama(url):\n",
        "  meta = dict()\n",
        "  page_soup = read_page(url)\n",
        "  title = find_title(page_soup)\n",
        "  meta.update({\"Title\": title})\n",
        "  description = find_description(page_soup)\n",
        "  meta.update({\"Description\": description})\n",
        "  meta_dict = find_meta1(page_soup)\n",
        "  meta.update(meta_dict)\n",
        "  meta_dict = find_meta2(page_soup)\n",
        "  meta.update(meta_dict)\n",
        "  casts = find_casts(page_soup)\n",
        "  meta.update({\"Casts\": casts})\n",
        "  return meta\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO9opjIrj29q"
      },
      "source": [
        "#Scripts\n",
        "# sample url for drama details\"https://mydramalist.com/36269-doctor-playbook\"\n",
        "base_url = \"https://mydramalist.com\"\n",
        "my_url =  \"https://mydramalist.com/search?adv=titles&ty=68&co=3&re=2016,2020&st=3&so=top\"\n",
        "\n",
        "kdrama_raw_list = list() #list of dict\n",
        "kdrama_list = list() #list of dict\n",
        "\n",
        "page_soup = read_page(my_url)\n",
        "total_result = find_total_result(page_soup)\n",
        "title_ids = find_all_titles(page_soup)\n",
        "total_pages = ceil(total_result/len(title_ids))\n",
        "\n",
        "for i in range(total_pages-1):\n",
        "  target_url = my_url+\"&page={}\".format(i+2)\n",
        "  page_soup = read_page(target_url)\n",
        "  title_ids.extend(find_all_titles(page_soup))\n",
        "\n",
        "for title in title_ids:\n",
        "  kdrama_raw = get_kdrama(base_url + title)\n",
        "  kdrama_raw_list.append(kdrama_raw)\n",
        "\n",
        "kdrama_copy = kdrama_raw_list.copy()\n",
        "\n",
        "for kdrama in kdrama_raw_list:\n",
        "  kdrama = preprocess_meta(kdrama)\n",
        "  kdrama_list.append(kdrama)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIx88t8mxWvc"
      },
      "source": [
        "import xlwt \n",
        "from xlwt import Workbook \n",
        "wb = Workbook() \n",
        "sheet1 = wb.add_sheet('Sheet 1') \n",
        "\n",
        "headers = [\"Title\", \"Description\", \"Genres\", \"Director\", \"Screenwriter\", \"Tags\", \"Episodes\", \n",
        "           \"Aired\", \"Aired On\", \"Original Network\", \"Score\", \"User_rated\", \"Watchers\", \"Ranked\", \"Popularity\", \"Casts\"]\n",
        "\n",
        "for i in range(len(headers)):\n",
        "  sheet1.write(0, i, headers[i])\n",
        "\n",
        "for row_idx, kdrama in enumerate(kdrama_list):\n",
        "  for col_idx in range(len(headers)):\n",
        "    try:\n",
        "      data = kdrama[headers[col_idx]]\n",
        "    except:\n",
        "      print(kdrama[\"Title\"])\n",
        "    if(type(data) == list or type(data) == bs4.element.ResultSet):\n",
        "      data = str(data)\n",
        "    sheet1.write(row_idx+1, col_idx, data)\n",
        "\n",
        "wb.save('xlwt example.xls') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNGbBvt5Rbxm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A_hyt51Rbcl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4gpzBFZRbYd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omjdyqm-RbVv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3XKwV76Kg9X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDlX27AeT_F6"
      },
      "source": [
        "# class kdrama:\n",
        "#   def __init__(self, title, description, genres, director, screen_writer, tags, episodes, \n",
        "#                aired, aired_on, network, rating, user_rated, total_watchers, rank, popularity, cast):\n",
        "#     self.title = title,#\n",
        "#     self.description = description,#\n",
        "#     self.genres = genres,#\n",
        "#     self.director = director,#\n",
        "#     self.screen_writer = screen_writer,#\n",
        "#     self.tags = tags,#\n",
        "#     self.episodes = episodes,#\n",
        "#     self.aired = aired,#\n",
        "#     self.aired_on = aired_on,#\n",
        "#     self.network = network,#\n",
        "#     self.rating = rating,#\n",
        "#     self.user_rated = user_rated, \n",
        "#     self.total_watchers = total_watchers,\n",
        "#     self.rank = rank#\n",
        "#     self.popularity = popularity#\n",
        "#     self.cast = classmethod\n",
        "\n",
        "#   def __str__(self):\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}